{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pandas, numpy, imports and reads the csv files \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "albums_file = \"./data/spotify_albums.csv\"\n",
    "artists_file = \"./data/spotify_artists.csv\"\n",
    "tracks_file = \"./data/spotify_tracks.csv\"\n",
    "albums = pd.read_csv(albums_file, header=0)\n",
    "artists = pd.read_csv(artists_file, header=0)\n",
    "tracks = pd.read_csv(tracks_file, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For each dataset, profile the data using head(), tail(), and .shape. Write a comment for each one, briefly explaining what this technique does, and what the output you got tells you about the dataset. '''\n",
    "\n",
    "# uses .head() to show the first (n) rows are at the beginning of each column\n",
    "# albums_head = albums.head()\n",
    "# artists_head = artists.head()\n",
    "# tracks_head = tracks.head()\n",
    "# print(albums_head, artists_head, tracks_head)\n",
    "\n",
    "# uses .tail() to show the last (n) rows are at the end of each column. print the result\n",
    "# albums_tail = albums.tail()\n",
    "# artists_tail = artists.tail()\n",
    "# tracks_tail = tracks.tail()\n",
    "# print(albums_tail, artists_tail, tracks_tail)\n",
    "\n",
    "# uses .shape to show how many rows and columns are in each dataset. print the result.\n",
    "# albums_shape = albums.shape\n",
    "# artists_shape = artists.shape\n",
    "# tracks_shape = tracks.shape\n",
    "# print(tracks_shape)\n",
    "# print(albums_shape, artists_shape, tracks_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# abc = \" \"\n",
    "# print(float(abc))\n",
    "# # For Artists:\n",
    "# # Write a map() function to replace the empty list ([]) entries in the genres column with NaNs (but don't alter the list entries in genres that contain values!)\n",
    "artists.fillna('NaN')\n",
    "\n",
    "#Map function to replace blank values in 'genres' with NaN.\n",
    "def map_genre (value):\n",
    "    if value =='[]':\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "artists['genres']= artists.genres.map(map_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 name release_date\n",
      "10  Beethoven: 6 Bagatelles & Piano Sonatas Nos. 3...   2019-03-01\n",
      "11                                Au Long de la Loire   2019-03-01\n",
      "12                                     I Still Miss U   2019-03-15\n",
      "13                                     Kolmekymppinen         1980\n",
      "14                                              Bruja   2018-04-24\n",
      "15                            Sonatas for two violins   2019-03-01\n",
      "16                                            Sir√®nes   2019-03-01\n",
      "17                                       Light of Day   2019-03-01\n",
      "18                                   Madame del Campo   2015-08-03\n",
      "19  Beethoven: Piano Concerto No. 2 & Triple Conce...   2019-03-01\n",
      "20                                      Violinsonaten   2019-03-01\n"
     ]
    }
   ],
   "source": [
    "''' For Albums, use .loc to show just rows 10-20 of the 'name' and 'release_date' columns '''\n",
    "\n",
    "# shows the values in rows 10-20 in columns name and release_date\n",
    "\n",
    "print(albums.loc[10:20, ['name', 'release_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Clean and normalize each dataset: \"\"\"\n",
    "''' remove duplicates from dataset '''\n",
    "\n",
    "# # determines if any duplicates are in the data set\n",
    "dupe_albums = albums.duplicated().any()\n",
    "dupe_artists = artists.duplicated().any()\n",
    "dupe_tracks = tracks.duplicated().any()\n",
    "print(dupe_albums, dupe_artists, dupe_tracks)\n",
    "\n",
    "\n",
    "# # # drops duplicates\n",
    "# albums = albums.drop_duplicates()\n",
    "# artists = artists.drop_duplicates()\n",
    "# tracks = tracks.drop_duplicates()\n",
    "\n",
    "\n",
    "# # retest to confirm that the dupes did in fact, drop\n",
    "# dupe_albums = albums.duplicated().any()\n",
    "# dupe_artists = artists.duplicated().any()\n",
    "# dupe_tracks = tracks.duplicated().any()\n",
    "# print(dupe_albums, dupe_artists, dupe_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For Tracks: \"\"\"\n",
    "\"\"\"  Print the names of the columns in Tracks  \"\"\"\n",
    "# prints the names of columns in the tracks data folder\n",
    "print(tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" drop the lyrics column \"\"\"\n",
    "# find the index number of the lyrics column\n",
    "tracks.drop('lyrics', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print the names of the Tracks columns again, to show that the 'lyrics' column has been dropped\"\"\"\n",
    "# prints names in tracks columns\n",
    "print(tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Using Pandas, perform the following joins, choosing the join type that you think is appropriate. Make a comment in your code file on why you chose that join type \"\"\"\n",
    "\"\"\"# Join artists and albums on the artist ID\"\"\"\n",
    "# merges artists and albums on ID. chose this one because they had it in common and inner merge seemed like the right way\n",
    "artists_albums = artists.merge(albums, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print the head() and shape of the resulting DataFrame \"\"\"\n",
    "artists_albums_head = artists_albums.head()\n",
    "artists_album_shape = artists_albums.shape\n",
    "print(artists_albums_head, artists_album_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Join albums and tracks on the album ID\"\"\"\n",
    "# checks for columns in common fieldsprint(albums.columns)\n",
    "print(tracks.columns)\n",
    "print(albums.columns)\n",
    "\n",
    "# renames artist_id column to artists_id\n",
    "albums.rename(columns = {'artist_id':'artists_id'}, inplace = True)\n",
    "\n",
    "# joins albums and tracks on album ID using the left merge to have all the album information even if the tracks arent on the list\n",
    "albums_tracks = albums.merge(tracks, how='inner', on='artists_id')\n",
    "\n",
    "# checks my work\n",
    "print(albums_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print the head() and shape of the resulting DataFrame \"\"\"\n",
    "albums_tracks_head = albums_tracks.head()\n",
    "albums_tracks_shape = albums_tracks.shape\n",
    "print(albums_tracks_head, albums_tracks_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use the Pandas to calculate some statistics on the data, and print the results:\"\"\"\n",
    "artists_data = artists.describe()\n",
    "albums_data = albums.describe()\n",
    "tracks_data =albums.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Haze\n",
       "1    Sasha\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Which artists appear the most times in the Artists data?\"\"\"\n",
    "# print(artists.columns)\n",
    "# print(artists.groupby(\"name\").max())\n",
    "artists['name'].value_counts()\n",
    "artists['name'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_popularity  name         \n",
      "100                Ariana Grande    1\n",
      "98                 Drake            1\n",
      "96                 Post Malone      1\n",
      "95                 XXXTENTACION     1\n",
      "                   Ozuna            1\n",
      "                   Khalid           1\n",
      "                   Juice WRLD       1\n",
      "94                 Travis Scott     1\n",
      "                   Queen            1\n",
      "                   Bad Bunny        1\n",
      "Name: name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Which artists have the highest 'artist_popularity' rankings? (list the top ten in descending order)\"\"\"\n",
    "# finds artists by popularity, reverses the list and then returns the top ten\n",
    "coolness = artists.groupby('artist_popularity')['name'].value_counts()\n",
    "coolness = coolness[::-1]\n",
    "print(coolness.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Point: How many albums came out in each year? (Notice that the values in the release_date column of Albums is in the format yyyy-mm-dd)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
