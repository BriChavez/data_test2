{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pandas, numpy, imports and reads the csv files \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "albums_file = \"./data/spotify_albums.csv\"\n",
    "artists_file = \"./data/spotify_artists.csv\"\n",
    "tracks_file = \"./data/spotify_tracks.csv\"\n",
    "albums = pd.read_csv(albums_file, header=0)\n",
    "artists = pd.read_csv(artists_file, header=0)\n",
    "tracks = pd.read_csv(tracks_file, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101939, 31)\n"
     ]
    }
   ],
   "source": [
    "''' For each dataset, profile the data using head(), tail(), and .shape. Write a comment for each one, briefly explaining what this technique does, and what the output you got tells you about the dataset. '''\n",
    "\n",
    "# uses .head() to show the first (n) rows are at the beginning of each column\n",
    "# albums_head = albums.head()\n",
    "# artists_head = artists.head()\n",
    "# tracks_head = tracks.head()\n",
    "# print(albums_head, artists_head, tracks_head)\n",
    "\n",
    "# uses .tail() to show the last (n) rows are at the end of each column. print the result\n",
    "# albums_tail = albums.tail()\n",
    "# artists_tail = artists.tail()\n",
    "# tracks_tail = tracks.tail()\n",
    "# print(albums_tail, artists_tail, tracks_tail)\n",
    "\n",
    "# uses .shape to show how many rows and columns are in each dataset. print the result.\n",
    "# albums_shape = albums.shape\n",
    "# artists_shape = artists.shape\n",
    "tracks_shape = tracks.shape\n",
    "print(tracks_shape)\n",
    "# print(albums_shape, artists_shape, tracks_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For Albums, use .loc to show just rows 10-20 of the 'name' and 'release_date' columns '''\n",
    "\n",
    "# shows the values in rows 10-20 in columns name and release_date\n",
    "albums.loc[10:20] , ['name' , 'release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Clean and normalize each dataset: \"\"\"\n",
    "''' remove duplicates from dataset '''\n",
    "\n",
    "# # determines if any duplicates are in the data set\n",
    "dupe_albums = albums.duplicated().any()\n",
    "dupe_artists = artists.duplicated().any()\n",
    "dupe_tracks = tracks.duplicated().any()\n",
    "print(dupe_albums, dupe_artists, dupe_tracks)\n",
    "\n",
    "\n",
    "# # # drops duplicates\n",
    "albums = albums.drop_duplicates()\n",
    "artists = artists.drop_duplicates()\n",
    "tracks = tracks.drop_duplicates()\n",
    "\n",
    "\n",
    "# # retest to confirm that the dupes did in fact, drop\n",
    "dupe_albums = albums.duplicated().any()\n",
    "dupe_artists = artists.duplicated().any()\n",
    "dupe_tracks = tracks.duplicated().any()\n",
    "# print(dupe_albums, dupe_artists, dupe_tracks)\n",
    "\n",
    "\n",
    "# # what happens when the dupes get droppin'\n",
    "# from pyspark.sql.functions import explode\n",
    "\n",
    "# dupe_drop = tracks.explode('danceability')\n",
    "# print(dupe_drop)\n",
    "# ,'liveness', 'loudness', 'popularity', 'tempo', 'time_signature', 'valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artists_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'mode', 'name', 'playlist', 'popularity',\n",
      "       'preview_url', 'speechiness', 'tempo', 'time_signature', 'track_href',\n",
      "       'track_name_prev', 'track_number', 'uri', 'valence', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" For Tracks: \"\"\"\n",
    "\"\"\"  Print the names of the columns in Tracks  \"\"\"\n",
    "# prints the names of columns in the tracks data folder\n",
    "print(tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" drop the lyrics column \"\"\"\n",
    "# find the index number of the lyrics column\n",
    "tracks.drop('lyrics', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artists_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'mode', 'name', 'playlist', 'popularity',\n",
      "       'preview_url', 'speechiness', 'tempo', 'time_signature', 'track_href',\n",
      "       'track_name_prev', 'track_number', 'uri', 'valence', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Print the names of the Tracks columns again, to show that the 'lyrics' column has been dropped\"\"\"\n",
    "# prints names in tracks columns\n",
    "print(tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Using Pandas, perform the following joins, choosing the join type that you think is appropriate. Make a comment in your code file on why you chose that join type \"\"\"\n",
    "\"\"\"# Join artists and albums on the artist ID\"\"\"\n",
    "# merges artists and albums on ID. chose this one because they had it in common and inner merge seemed like the right way\n",
    "artists_albums = artists.merge(albums, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0_x, artist_popularity, followers, genres, id, name_x, track_id_x, track_name_prev_x, type_x, Unnamed: 0_y, album_type, artist_id, available_markets, external_urls, href, images, name_y, release_date, release_date_precision, total_tracks, track_id_y, track_name_prev_y, uri, type_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 24 columns] (0, 24)\n",
      "Index(['Unnamed: 0', 'album_type', 'artist_id', 'available_markets',\n",
      "       'external_urls', 'href', 'id', 'images', 'name', 'release_date',\n",
      "       'release_date_precision', 'total_tracks', 'track_id', 'track_name_prev',\n",
      "       'uri', 'type'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artists_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'mode', 'name', 'playlist', 'popularity',\n",
      "       'preview_url', 'speechiness', 'tempo', 'time_signature', 'track_href',\n",
      "       'track_name_prev', 'track_number', 'uri', 'valence', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" print the head() and shape of the resulting DataFrame \"\"\"\n",
    "artists_albums_head = artists_albums.head()\n",
    "artists_album_shape = artists_albums.shape\n",
    "print(artists_albums_head, artists_album_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artists_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'mode', 'name', 'playlist', 'popularity',\n",
      "       'preview_url', 'speechiness', 'tempo', 'time_signature', 'track_href',\n",
      "       'track_name_prev', 'track_number', 'uri', 'valence', 'type'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'album_type', 'artists_id', 'available_markets',\n",
      "       'external_urls', 'href', 'id', 'images', 'name', 'release_date',\n",
      "       'release_date_precision', 'total_tracks', 'track_id', 'track_name_prev',\n",
      "       'uri', 'type'],\n",
      "      dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0_x, album_type, artists_id, available_markets_x, external_urls, href_x, id_x, images, name_x, release_date, release_date_precision, total_tracks, track_id, track_name_prev_x, uri_x, type_x, Unnamed: 0_y, acousticness, album_id, analysis_url, available_markets_y, country, danceability, disc_number, duration_ms, energy, href_y, id_y, instrumentalness, key, liveness, loudness, mode, name_y, playlist, popularity, preview_url, speechiness, tempo, time_signature, track_href, track_name_prev_y, track_number, uri_y, valence, type_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Join albums and tracks on the album ID\"\"\"\n",
    "# checks for columns in common fieldsprint(albums.columns)\n",
    "print(tracks.columns)\n",
    "print(albums.columns)\n",
    "\n",
    "# renames artist_id column to artists_id\n",
    "albums.rename(columns = {'artist_id':'artists_id'}, inplace = True)\n",
    "\n",
    "# joins albums and tracks on album ID using the left merge to have all the album information even if the tracks arent on the list\n",
    "albums_tracks = albums.merge(tracks, how='inner', on='artists_id')\n",
    "\n",
    "# checks my work\n",
    "print(albums_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0_x, album_type, artists_id, available_markets_x, external_urls, href_x, id_x, images, name_x, release_date, release_date_precision, total_tracks, track_id, track_name_prev_x, uri_x, type_x, Unnamed: 0_y, acousticness, album_id, analysis_url, available_markets_y, country, danceability, disc_number, duration_ms, energy, href_y, id_y, instrumentalness, key, liveness, loudness, mode, name_y, playlist, popularity, preview_url, speechiness, tempo, time_signature, track_href, track_name_prev_y, track_number, uri_y, valence, type_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 46 columns] (0, 46)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" print the head() and shape of the resulting DataFrame \"\"\"\n",
    "albums_tracks_head = albums_tracks.head()\n",
    "albums_tracks_shape = albums_tracks.shape\n",
    "print(albums_tracks_head, albums_tracks_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>total_tracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75511.000000</td>\n",
       "      <td>75511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37755.000000</td>\n",
       "      <td>8.235807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21798.292425</td>\n",
       "      <td>11.669811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18877.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37755.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56632.500000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75510.000000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  total_tracks\n",
       "count  75511.000000  75511.000000\n",
       "mean   37755.000000      8.235807\n",
       "std    21798.292425     11.669811\n",
       "min        0.000000      1.000000\n",
       "25%    18877.500000      1.000000\n",
       "50%    37755.000000      5.000000\n",
       "75%    56632.500000     12.000000\n",
       "max    75510.000000    977.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Use the Pandas to calculate some statistics on the data, and print the results:\"\"\"\n",
    "artists_data = artists.describe()\n",
    "albums_data = albums.describe()\n",
    "tracks_data =albums.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# \n",
    "\n",
    "# Which artists appear the most times in the Artists data?\n",
    "# Which artists have the highest 'artist_popularity' rankings? (list the top ten in descending order)\n",
    "# Include comments as needed in your code to explain what your code is doing, and add a brief description of your project in your README.\n",
    "\n",
    "# Bonus Point: How many albums came out in each year? (Notice that the values in the release_date column of Albums is in the format yyyy-mm-dd)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
